{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:32:02.151234Z",
     "iopub.status.busy": "2024-11-27T14:32:02.150766Z",
     "iopub.status.idle": "2024-11-27T14:36:10.238866Z",
     "shell.execute_reply": "2024-11-27T14:36:10.237860Z",
     "shell.execute_reply.started": "2024-11-27T14:32:02.151180Z"
    },
    "id": "2eSvM9zX_2d3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install tensorboard\n",
    "!pip install gdown\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ['UNSLOTH_RETURN_LOGITS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:36:10.240907Z",
     "iopub.status.busy": "2024-11-27T14:36:10.240625Z",
     "iopub.status.idle": "2024-11-27T14:36:45.598612Z",
     "shell.execute_reply": "2024-11-27T14:36:45.597929Z",
     "shell.execute_reply.started": "2024-11-27T14:36:10.240881Z"
    },
    "id": "QmUBVEnvCDJv",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.11: Fast Qwen2 patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: Tesla P100-PCIE-16GB. Max memory: 15.888 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 6.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab941a1593c49dab44831899e82b374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed00987576d46cf8c3c20218dd8eda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7352a8b90d704d20bfc06d667fafdc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb84af839f7446bbdf5bb6b2fa3ee41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8616f15946c341209063a6b5c7209bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b583ceb6abde45dd85c4b37164dfa80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257c2633eecc4856a38976d1caf7db72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2e119a504a4d63837d5592902b9428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-Coder-3B-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:36:45.600399Z",
     "iopub.status.busy": "2024-11-27T14:36:45.599677Z",
     "iopub.status.idle": "2024-11-27T14:36:50.967986Z",
     "shell.execute_reply": "2024-11-27T14:36:50.967020Z",
     "shell.execute_reply.started": "2024-11-27T14:36:45.600367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.11 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, \n",
    "    bias = \"none\", \n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 3407,\n",
    "    use_rslora = False, \n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:36:50.970120Z",
     "iopub.status.busy": "2024-11-27T14:36:50.969828Z",
     "iopub.status.idle": "2024-11-27T14:37:09.660576Z",
     "shell.execute_reply": "2024-11-27T14:37:09.659014Z",
     "shell.execute_reply.started": "2024-11-27T14:36:50.970091Z"
    },
    "id": "6Z45_ods08sq",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dBLjJhIV8olnOLLHnS_j0wFaPc1CzuZP\n",
      "To: /kaggle/working/test_dataset.csv\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 389k/389k [00:00<00:00, 102MB/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NLF9FeN3r9NkiNHsR2b1pweczlDw37kx\n",
      "To: /kaggle/working/train_dataset.csv\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.56M/1.56M [00:00<00:00, 162MB/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CJ6F9LUcusyEKxihsjj3TqL2ofMwT7J5\n",
      "To: /kaggle/working/val_dataset.csv\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80.1k/80.1k [00:00<00:00, 71.5MB/s]\n",
      "                                                Code  \\\n",
      "0  @Nonnull\\n        public Modal build()\\n      ...   \n",
      "1  public static Snowflake of(final Instant times...   \n",
      "2                    boolean isMentionRepliedUser();   \n",
      "3  public UnknownChannel(final GatewayDiscordClie...   \n",
      "4  public int getTypeRaw()\\n    {\\n        return...   \n",
      "\n",
      "                                             JavaDoc  \\\n",
      "0  /**\\n         * Builds and returns the {@link ...   \n",
      "1  /**\\n     * Constructs a {@code Snowflake} uti...   \n",
      "2  /**\\n     * Whether this message would mention...   \n",
      "3  /**\\n     * Constructs an {@code UnknownChanne...   \n",
      "4  /**\\n     * The raw type value used to derive ...   \n",
      "\n",
      "                                   Package  \n",
      "0  net.dv8tion.jda.api.interactions.modals  \n",
      "1                    discord4j.common.util  \n",
      "2       net.dv8tion.jda.api.utils.messages  \n",
      "3     discord4j.core.object.entity.channel  \n",
      "4                net.dv8tion.jda.api.audit  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!gdown 1dBLjJhIV8olnOLLHnS_j0wFaPc1CzuZP\n",
    "!gdown 1NLF9FeN3r9NkiNHsR2b1pweczlDw37kx\n",
    "!gdown 1CJ6F9LUcusyEKxihsjj3TqL2ofMwT7J5\n",
    "\n",
    "# Load the Excel file\n",
    "train_file_path = \"/kaggle/working/train_dataset.csv\"\n",
    "test_file_path = \"/kaggle/working/test_dataset.csv\"\n",
    "val_file_path = \"/kaggle/working/val_dataset.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "val_df = pd.read_csv(val_file_path)\n",
    "\n",
    "# Display the first few rows of the train and test sets to ensure everything works fine\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:09.662743Z",
     "iopub.status.busy": "2024-11-27T14:37:09.662456Z",
     "iopub.status.idle": "2024-11-27T14:37:09.670714Z",
     "shell.execute_reply": "2024-11-27T14:37:09.669348Z",
     "shell.execute_reply.started": "2024-11-27T14:37:09.662716Z"
    },
    "id": "JyMFCcbe2Smp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm_few_shot_examples = \"\"\"\n",
    "Here are a few examples\n",
    "\n",
    "@Nonnull\n",
    "public Modal build() {\n",
    "    Checks.check(!components.isEmpty(), \"Cannot make a modal without components!\");\n",
    "    Checks.check(components.size() <= MAX_COMPONENTS, \"Cannot make a modal with more than 5 components!\");\n",
    "\n",
    "    return new ModalImpl(id, title, components);\n",
    "}\n",
    "\n",
    "net.dv8tion.jda.api.interactions.modals\n",
    "\n",
    "/**\n",
    " * Builds and returns the {@link Modal}.\n",
    " *\n",
    " * @throws IllegalArgumentException\n",
    " *         <ul>\n",
    " *             <li>If no components are added</li>\n",
    " *             <li>If more than {@value MAX_COMPONENTS} component layouts are added</li>\n",
    " *         </ul>\n",
    " *\n",
    " * @return A Modal\n",
    " */\n",
    "\n",
    "@Nonnull\n",
    "@CheckReturnValue\n",
    "PermissionOverrideAction upsertPermissionOverride(@Nonnull IPermissionHolder permissionHolder);\n",
    "\n",
    "net.dv8tion.jda.api.entities.channel.attribute\n",
    "\n",
    "/**\n",
    " * Creates a new override or updates an existing one.\n",
    " * <br>This is similar to calling {@link PermissionOverride#getManager()} if an override exists.\n",
    " *\n",
    " * @param  permissionHolder\n",
    " *         The Member/Role for the override.\n",
    " *\n",
    " * @throws net.dv8tion.jda.api.exceptions.InsufficientPermissionException\n",
    " *         If we don't have the permission to {@link net.dv8tion.jda.api.Permission#MANAGE_PERMISSIONS MANAGE_PERMISSIONS}.\n",
    " * @throws java.lang.IllegalArgumentException\n",
    " *         If the provided permission holder is null or not from this guild.\n",
    " *\n",
    " * @return {@link net.dv8tion.jda.api.requests.restaction.PermissionOverrideAction}\n",
    " *         <br>With the current settings of an existing override or a fresh override with no permissions set.\n",
    " *\n",
    " * @see    PermissionOverrideAction#clear(long)\n",
    " * @see    PermissionOverrideAction#grant(long)\n",
    " * @see    PermissionOverrideAction#deny(long)\n",
    " */\n",
    "\n",
    "public LegacyEmbedCreateSpec setFooter(String text, @Nullable String iconUrl) {\n",
    "    requestBuilder.footer(EmbedFooterData.builder()\n",
    "        .text(text)\n",
    "        .iconUrl(iconUrl == null ? Possible.absent() : Possible.of(iconUrl))\n",
    "        .build());\n",
    "    return this;\n",
    "}\n",
    "\n",
    "discord4j.core.spec.legacy\n",
    "\n",
    "/**\n",
    " * Sets the footer of the embed.\n",
    " *\n",
    " * @param text The footer text.\n",
    " * @param iconUrl An icon URL to display in the footer.\n",
    " * @return This spec.\n",
    " */\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:09.673718Z",
     "iopub.status.busy": "2024-11-27T14:37:09.671868Z",
     "iopub.status.idle": "2024-11-27T14:37:09.725618Z",
     "shell.execute_reply": "2024-11-27T14:37:09.724774Z",
     "shell.execute_reply.started": "2024-11-27T14:37:09.673668Z"
    },
    "id": "28ktBT5_VVnI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm_one_shot_example = \"\"\"\n",
    "Here are an example\n",
    "\n",
    "@Nonnull\n",
    "public Modal build() {\n",
    "    Checks.check(!components.isEmpty(), \"Cannot make a modal without components!\");\n",
    "    Checks.check(components.size() <= MAX_COMPONENTS, \"Cannot make a modal with more than 5 components!\");\n",
    "\n",
    "    return new ModalImpl(id, title, components);\n",
    "}\n",
    "\n",
    "net.dv8tion.jda.api.interactions.modals\n",
    "\n",
    "/**\n",
    " * Builds and returns the {@link Modal}.\n",
    " *\n",
    " * @throws IllegalArgumentException\n",
    " *         <ul>\n",
    " *             <li>If no components are added</li>\n",
    " *             <li>If more than {@value MAX_COMPONENTS} component layouts are added</li>\n",
    " *         </ul>\n",
    " *\n",
    " * @return A Modal\n",
    " */\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:09.727297Z",
     "iopub.status.busy": "2024-11-27T14:37:09.726868Z",
     "iopub.status.idle": "2024-11-27T14:37:09.946775Z",
     "shell.execute_reply": "2024-11-27T14:37:09.945690Z",
     "shell.execute_reply.started": "2024-11-27T14:37:09.727229Z"
    },
    "id": "LjY75GoYUCB8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a029ba55128a44548b5f58e44749bc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fa1a3daff0474789cb449d9659e6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d18a924b114f4394ead1ad5dd9bfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebf14bb4e404e108930de0d11e9bbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96dbab6ad564e78adc914018c400587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_prompt = \"\"\"Given a function as Code and package of that function as Package, the task is to generate javadoc for the function.\n",
    "\n",
    "### Code:\n",
    "{}\n",
    "\n",
    "### Package:\n",
    "{}\n",
    "\n",
    "### JavaDoc:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "EOS_TOKEN = \"</eos>\" # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    codes = examples[\"Code\"]\n",
    "    packages = examples[\"Package\"]\n",
    "    javadocs = examples[\"JavaDoc\"]\n",
    "    texts = []\n",
    "    for code, package, javadoc in zip(codes, packages, javadocs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = llm_prompt.format(code, package, javadoc) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "def formatting_few_shot_prompts_func(examples):\n",
    "    codes = examples[\"Code\"]\n",
    "    packages = examples[\"Package\"]\n",
    "    javadocs = examples[\"JavaDoc\"]\n",
    "    texts = []\n",
    "    for code, package, javadoc in zip(codes, packages, javadocs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = llm_prompt.format(code, package, javadoc) + \"\\n\" +llm_few_shot_examples + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "def formatting_one_shot_prompts_func(examples):\n",
    "    codes = examples[\"Code\"]\n",
    "    packages = examples[\"Package\"]\n",
    "    javadocs = examples[\"JavaDoc\"]\n",
    "    texts = []\n",
    "    for code, package, javadoc in zip(codes, packages, javadocs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = llm_prompt.format(code, package, javadoc) + \"\\n\" +llm_one_shot_example + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "test_dataset = test_dataset.map(formatting_prompts_func, batched=True)\n",
    "test_few_shot = test_dataset.map(formatting_few_shot_prompts_func, batched=True)\n",
    "test_one_shot = test_dataset.map(formatting_one_shot_prompts_func, batched=True)\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:09.948223Z",
     "iopub.status.busy": "2024-11-27T14:37:09.947979Z",
     "iopub.status.idle": "2024-11-27T14:37:09.954797Z",
     "shell.execute_reply": "2024-11-27T14:37:09.953965Z",
     "shell.execute_reply.started": "2024-11-27T14:37:09.948199Z"
    },
    "id": "lQjGg5egPjb4",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Code': 'public Integer getAnswerId() {\\n        return this.data.answerId().get(); // We can safely call get() here because the answerId is always present\\n    }',\n",
       " 'JavaDoc': '/**\\n     * Gets the answer id of this poll answer.\\n     *\\n     * @return the answer id of this poll answer\\n     */',\n",
       " 'Package': 'discord4j.core.object.entity.poll',\n",
       " 'text': 'Given a function as Code and package of that function as Package, the task is to generate javadoc for the function.\\n\\n### Code:\\npublic Integer getAnswerId() {\\n        return this.data.answerId().get(); // We can safely call get() here because the answerId is always present\\n    }\\n\\n### Package:\\ndiscord4j.core.object.entity.poll\\n\\n### JavaDoc:\\n/**\\n     * Gets the answer id of this poll answer.\\n     *\\n     * @return the answer id of this poll answer\\n     */</eos>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:09.956294Z",
     "iopub.status.busy": "2024-11-27T14:37:09.955996Z",
     "iopub.status.idle": "2024-11-27T14:37:12.192375Z",
     "shell.execute_reply": "2024-11-27T14:37:12.191654Z",
     "shell.execute_reply.started": "2024-11-27T14:37:09.956237Z"
    },
    "id": "6sBbH7UYFgbN",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0383d9bcd42f4b0e851a061a49fc1ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2725c16e9a5649b796af4c347cbfa90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2af6a6290c14d3e9a01dfe43e83356f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9228d9e1b174cff8b53e08263ad90a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load BLEU and ROUGE metrics using the evaluate library\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak.\n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return pred_ids, labels\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions[0]\n",
    "\n",
    "    # Replace -100 with the pad token ID\n",
    "    pred_ids = np.where(pred_ids == -100, tokenizer.pad_token_id, pred_ids)\n",
    "    labels_ids = np.where(labels_ids == -100, tokenizer.pad_token_id, labels_ids)\n",
    "\n",
    "    # Decode the predicted and reference sequences\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_output = rouge_metric.compute(\n",
    "        predictions=pred_str,\n",
    "        references=label_str,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    )\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_output = bleu_metric.compute(\n",
    "        predictions=pred_str,\n",
    "        references=[[ref] for ref in label_str]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": round(bleu_output[\"bleu\"], 4),\n",
    "        \"R1\": round(rouge_output[\"rouge1\"], 4),\n",
    "        \"R2\": round(rouge_output[\"rouge2\"], 4),\n",
    "        \"RL\": round(rouge_output[\"rougeL\"], 4),\n",
    "        \"RLsum\": round(rouge_output[\"rougeLsum\"], 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:12.195486Z",
     "iopub.status.busy": "2024-11-27T14:37:12.195169Z",
     "iopub.status.idle": "2024-11-27T14:37:18.233697Z",
     "shell.execute_reply": "2024-11-27T14:37:18.232826Z",
     "shell.execute_reply.started": "2024-11-27T14:37:12.195459Z"
    },
    "id": "kqF3EQtLlLG9",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b57cfe20e8cd89d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b57cfe20e8cd89d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/outputs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:37:18.234886Z",
     "iopub.status.busy": "2024-11-27T14:37:18.234654Z",
     "iopub.status.idle": "2024-11-27T14:40:42.031281Z",
     "shell.execute_reply": "2024-11-27T14:40:42.030410Z",
     "shell.execute_reply.started": "2024-11-27T14:37:18.234863Z"
    },
    "id": "95_Nn-89DhsL",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e43b3a59e5a486d8c6d2cfe18f6d018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd4af1818814930bfe1a08eb417a896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.2422244548797607,\n",
       " 'eval_model_preparation_time': 0.0091,\n",
       " 'eval_BLEU': 0.3362,\n",
       " 'eval_R1': 0.562,\n",
       " 'eval_R2': 0.277,\n",
       " 'eval_RL': 0.4627,\n",
       " 'eval_RLsum': 0.5431,\n",
       " 'eval_runtime': 199.9758,\n",
       " 'eval_samples_per_second': 3.475,\n",
       " 'eval_steps_per_second': 1.74}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"tensorboard\",\n",
    "         # Evaluation settings\n",
    "        evaluation_strategy = \"steps\",  \n",
    "        eval_steps = 5,                \n",
    "        save_steps = 50,               \n",
    "        load_best_model_at_end = True,  \n",
    "    ),\n",
    ")\n",
    "# For zero shot results\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:40:42.040924Z",
     "iopub.status.busy": "2024-11-27T14:40:42.040673Z",
     "iopub.status.idle": "2024-11-27T14:45:54.566061Z",
     "shell.execute_reply": "2024-11-27T14:45:54.565127Z",
     "shell.execute_reply.started": "2024-11-27T14:40:42.040900Z"
    },
    "id": "RqMLw83tWfI1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752488102f19443a9cbbb3e8665df44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45986b553bc4b1b88148860d93e4483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 04:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7619190216064453,\n",
       " 'eval_model_preparation_time': 0.0101,\n",
       " 'eval_BLEU': 0.4101,\n",
       " 'eval_R1': 0.6457,\n",
       " 'eval_R2': 0.3243,\n",
       " 'eval_RL': 0.5263,\n",
       " 'eval_RLsum': 0.6294,\n",
       " 'eval_runtime': 308.6297,\n",
       " 'eval_samples_per_second': 2.252,\n",
       " 'eval_steps_per_second': 1.128}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For one shot results\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_one_shot, #adding one shot\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, \n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 5, \n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"tensorboard\",\n",
    "         # Evaluation settings\n",
    "        evaluation_strategy = \"steps\",  \n",
    "        eval_steps = 5,                \n",
    "        save_steps = 50,              \n",
    "        load_best_model_at_end = True,  \n",
    "    ),\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:45:54.567546Z",
     "iopub.status.busy": "2024-11-27T14:45:54.567293Z",
     "iopub.status.idle": "2024-11-27T14:55:58.211933Z",
     "shell.execute_reply": "2024-11-27T14:55:58.210916Z",
     "shell.execute_reply.started": "2024-11-27T14:45:54.567523Z"
    },
    "id": "8d_sJVf73MHU",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4048c2443ad4a969a4e2cdb70a2a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498a6325a02b430b9fcff2e1e46dbd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 08:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4268790483474731,\n",
       " 'eval_model_preparation_time': 0.0096,\n",
       " 'eval_BLEU': 0.4743,\n",
       " 'eval_R1': 0.6852,\n",
       " 'eval_R2': 0.3774,\n",
       " 'eval_RL': 0.5708,\n",
       " 'eval_RLsum': 0.6783,\n",
       " 'eval_runtime': 599.6152,\n",
       " 'eval_samples_per_second': 1.159,\n",
       " 'eval_steps_per_second': 0.58}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For few shot results\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_few_shot,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, \n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 5, \n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"tensorboard\",\n",
    "         # Evaluation settings\n",
    "        evaluation_strategy = \"steps\",  \n",
    "        eval_steps = 5,                \n",
    "        save_steps = 50,               \n",
    "        load_best_model_at_end = True,  # Load the best model at the end of training\n",
    "    ),\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:55:58.213616Z",
     "iopub.status.busy": "2024-11-27T14:55:58.213300Z",
     "iopub.status.idle": "2024-11-27T14:56:01.751697Z",
     "shell.execute_reply": "2024-11-27T14:56:01.750681Z",
     "shell.execute_reply.started": "2024-11-27T14:55:58.213588Z"
    },
    "id": "53ShhVPp8DCb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dedf129676244bf876e8b083a090cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166ec8c46e84320ad1f70d9c9293449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset, #setting up the val dataset here\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, \n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 5, \n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"tensorboard\",\n",
    "         # Evaluation settings\n",
    "        evaluation_strategy = \"steps\",  \n",
    "        eval_steps = 20,                # Evaluate every 20 steps\n",
    "        save_steps = 60,               # Save the model every 60 steps\n",
    "        load_best_model_at_end = True,  # Load the best model at the end of training\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T14:56:01.753408Z",
     "iopub.status.busy": "2024-11-27T14:56:01.753095Z",
     "iopub.status.idle": "2024-11-27T18:55:58.762881Z",
     "shell.execute_reply": "2024-11-27T18:55:58.762054Z",
     "shell.execute_reply.started": "2024-11-27T14:56:01.753381Z"
    },
    "id": "yqxqAZ7KJ4oL",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 2,777 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 32 | Total steps = 435\n",
      " \"-____-\"     Number of trainable parameters = 29,933,568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='435' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [435/435 3:59:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rl</th>\n",
       "      <th>Rlsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>0.852805</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.758274</td>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.693258</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.749500</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>0.708100</td>\n",
       "      <td>0.744900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.639557</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.759800</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>0.722600</td>\n",
       "      <td>0.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>0.593062</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.769600</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.737300</td>\n",
       "      <td>0.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>0.564764</td>\n",
       "      <td>0.539700</td>\n",
       "      <td>0.776700</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.541105</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>0.749600</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.561100</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.565800</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.758300</td>\n",
       "      <td>0.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.507794</td>\n",
       "      <td>0.568700</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.659200</td>\n",
       "      <td>0.759600</td>\n",
       "      <td>0.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.499548</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.783600</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>0.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.490487</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.787900</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.762700</td>\n",
       "      <td>0.785600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.483025</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.792800</td>\n",
       "      <td>0.672300</td>\n",
       "      <td>0.767300</td>\n",
       "      <td>0.790700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.472824</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.769200</td>\n",
       "      <td>0.792300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.478767</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.677300</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.795400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.470725</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>0.471382</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.461450</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>0.796500</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.481258</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.684100</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.478616</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.682600</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>0.793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.475095</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.796600</td>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.472175</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.775600</td>\n",
       "      <td>0.795900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T18:55:58.764196Z",
     "iopub.status.busy": "2024-11-27T18:55:58.763952Z",
     "iopub.status.idle": "2024-11-27T18:56:02.345618Z",
     "shell.execute_reply": "2024-11-27T18:56:02.344814Z",
     "shell.execute_reply.started": "2024-11-27T18:55:58.764173Z"
    },
    "id": "S8BnLvbJ8LvY",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f38dff77a84af1b4686535fe7c5846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef1200fcca7426f925be46b3959d856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset, \n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, \n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 5, \n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"tensorboard\",\n",
    "         # Evaluation settings\n",
    "        evaluation_strategy = \"steps\", \n",
    "        eval_steps = 5,                \n",
    "        save_steps = 50,               \n",
    "        load_best_model_at_end = True,  # Load the best model at the end of training\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T18:56:02.347634Z",
     "iopub.status.busy": "2024-11-27T18:56:02.347371Z",
     "iopub.status.idle": "2024-11-27T18:59:18.320174Z",
     "shell.execute_reply": "2024-11-27T18:59:18.319328Z",
     "shell.execute_reply.started": "2024-11-27T18:56:02.347610Z"
    },
    "id": "B3VL_hIlCmof",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5060594081878662,\n",
       " 'eval_model_preparation_time': 0.0104,\n",
       " 'eval_BLEU': 0.5763,\n",
       " 'eval_R1': 0.7936,\n",
       " 'eval_R2': 0.6737,\n",
       " 'eval_RL': 0.7676,\n",
       " 'eval_RLsum': 0.7908,\n",
       " 'eval_runtime': 195.9505,\n",
       " 'eval_samples_per_second': 3.547,\n",
       " 'eval_steps_per_second': 1.776}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For fine tuned results\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
